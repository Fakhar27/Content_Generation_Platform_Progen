version: '3.8'

services:
  # Build the base image first
  base-image:
    build:
      context: ./ai-services/base-image
      dockerfile: Dockerfile
    image: progen-base-image:latest
    deploy:
      replicas: 0  # This service doesn't need to run, just build

  frontend:
    build:
      context: ./Fyp-Frontend-2
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=${NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY}
        - NEXT_PUBLIC_SUPABASE_URL=${NEXT_PUBLIC_SUPABASE_URL}
        - NEXT_PUBLIC_SUPABASE_SERVICE_KEY=${NEXT_PUBLIC_SUPABASE_SERVICE_KEY}
        - BACKEND_URL=http://backend:8000
        - NEXT_PUBLIC_CLERK_SIGN_IN_URL=${NEXT_PUBLIC_CLERK_SIGN_IN_URL}
        - NEXT_PUBLIC_CLERK_SIGN_IN_FALLBACK_REDIRECT_URL=${NEXT_PUBLIC_CLERK_SIGN_IN_FALLBACK_REDIRECT_URL}
        - NEXT_PUBLIC_CLERK_SIGN_UP_FALLBACK_REDIRECT_URL=${NEXT_PUBLIC_CLERK_SIGN_UP_FALLBACK_REDIRECT_URL}
        - NEXT_PUBLIC_DISABLE_OVERLAY=${NEXT_PUBLIC_DISABLE_OVERLAY}
    ports:
      - "3000:3000"
    depends_on:
      - backend
    networks:
      - progen-network

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - ELEVENLABS_API_KEY=${ELEVENLABS_API_KEY}
      - LANGSMITH_TRACING=${LANGSMITH_TRACING}
      - LANGSMITH_ENDPOINT=${LANGSMITH_ENDPOINT}
      - LANGSMITH_API_KEY=${LANGSMITH_API_KEY}
      - LANGSMITH_PROJECT=${LANGSMITH_PROJECT}
      - CO_API_KEY=${CO_API_KEY}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_STORAGE_BUCKET_NAME=${AWS_STORAGE_BUCKET_NAME}
      - AWS_S3_REGION_NAME=${AWS_S3_REGION_NAME}
      - HUGGINGFACE_API_KEY=${HUGGINGFACE_API_KEY}
      - IMAGE_SERVICE_URL=http://image-service:5000
      - VOICE_SERVICE_URL=http://voice-service:5000
      - WHISPER_SERVICE_URL=http://whisper-service:5000
      - DEBUG=True
      - ALLOWED_HOSTS=*
      - CORS_ALLOWED_ORIGINS=http://localhost:3000,http://frontend:3000
    depends_on:
      - image-service
      - voice-service
      - whisper-service
    networks:
      - progen-network

  image-service:
    build:
      context: ./ai-services/image-service
      dockerfile: Dockerfile
    depends_on:
      - base-image  # Ensure base image is built first
    ports:
      - "5001:5000"
    volumes:
      - shared-model-cache:/root/.cache/huggingface  # Share cache between services
    networks:
      - progen-network

  voice-service:
    build:
      context: ./ai-services/voice-service
      dockerfile: Dockerfile
    depends_on:
      - base-image  # Ensure base image is built first
    ports:
      - "5002:5000"
    volumes:
      - shared-model-cache:/root/.cache/huggingface  # Share cache between services
    networks:
      - progen-network

  whisper-service:
    build:
      context: ./ai-services/whisper-service
      dockerfile: Dockerfile
    depends_on:
      - base-image  # Ensure base image is built first
    ports:
      - "5003:5000"
    volumes:
      - shared-model-cache:/root/.cache/huggingface  # Share cache between services
    networks:
      - progen-network

networks:
  progen-network:
    driver: bridge

volumes:
  shared-model-cache:  # This allows all services to share the downloaded models